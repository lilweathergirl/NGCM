# -*- coding: utf-8 -*-
"""inference_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/google-research/neuralgcm/blob/main/docs/inference_demo.ipynb
"""

# if necessary, install NeuralGCM and dependencies
#! pip install -q -U neuralgcm dinosaur-dycore gcsfs

"""# Forecasting quick start

This notebook uses ERA5 data and pretrained NeuralGCM model to make a weather forecast.

The forecast is made in 3 steps:
1. Slice of ERA5 data is regridded to model resolution
2. NeuralGCM model state is initialized and rolled out
3. Predictions and reference trajectory are combined for visualization

By default the notebook uses intermediate deterministic NeuralGCM 1.4째 model. Other available checkpoints include deterministic 0.7째, 2.8째 and stochastic 1.4째 NeuralGCM variations.

```{tip}
You can run this notebook yourself in [Google Colab](https://colab.research.google.com/github/google-research/neuralgcm/blob/main/docs/inference_demo.ipynb). We recommend using a GPU or TPU runtime due to high memory and compute requirements.
```
"""


import gcsfs
import jax
import numpy as np
import pickle
import xarray
import xarray as xr
import pandas as pd
import matplotlib.pyplot as plt
import os
from dinosaur import horizontal_interpolation
from dinosaur import spherical_harmonic
from dinosaur import xarray_utils
import neuralgcm

gcs = gcsfs.GCSFileSystem(token='anon')

"""## Load a pre-trained NeuralGCM model

```{caution}
Trained model weights are licensed for non-commercial use, under the Creative Commons [Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/) license (CC BY-NC-SA 4.0).
```

Pre-trained model checkpoints from the NeuralGCM paper are [available for download](https://console.cloud.google.com/storage/browser/gresearch/neuralgcm/04_30_2024) on Google Cloud Storage:

- Deterministic models:
    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_0_7_deg.pkl`
    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_1_4_deg.pkl`
    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_2_8_deg.pkl`
- Stochastic models:
    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_stochastic_1_4_deg.pkl`


"""

# @param ['neural_gcm_dynamic_forcing_deterministic_0_7_deg.pkl', 'neural_gcm_dynamic_forcing_deterministic_1_4_deg.pkl', 'neural_gcm_dynamic_forcing_deterministic_2_8_deg.pkl', 'neural_gcm_dynamic_forcing_stochastic_1_4_deg.pkl'] {type: "string"}
model_name = 'neural_gcm_dynamic_forcing_deterministic_1_4_deg.pkl'

with gcs.open(f'gs://gresearch/neuralgcm/04_30_2024/{model_name}', 'rb') as f:
    ckpt = pickle.load(f)

model = neuralgcm.PressureLevelModel.from_checkpoint(ckpt)

"""## Load ERA5 data from GCP/Zarr

See {doc}`datasets` for details.

Select out a few days of data:
"""

era5_path = 'gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3'
full_era5 = xarray.open_zarr(gcs.get_mapper(era5_path), chunks=None)


demo_start_time = '2002-05-22'
demo_end_time = '2002-06-01'
data_inner_steps = 24  # process every 24th hour

sliced_era5 = (
    full_era5
    [model.input_variables + model.forcing_variables]
    .pipe(
        xarray_utils.selective_temporal_shift,
        variables=model.forcing_variables,
        time_shift='24 hours',
    )
    .sel(time=slice(demo_start_time, demo_end_time, data_inner_steps))
    .compute()
)

"""Regrid to NeuralGCM's native resolution:"""

era5_grid = spherical_harmonic.Grid(
    latitude_nodes=full_era5.sizes['latitude'],
    longitude_nodes=full_era5.sizes['longitude'],
    latitude_spacing=xarray_utils.infer_latitude_spacing(full_era5.latitude),
    longitude_offset=xarray_utils.infer_longitude_offset(full_era5.longitude),
)
regridder = horizontal_interpolation.ConservativeRegridder(
    era5_grid, model.data_coords.horizontal, skipna=True
)
eval_era5 = xarray_utils.regrid(sliced_era5, regridder)
eval_era5 = xarray_utils.fill_nan_with_nearest(eval_era5)

"""## Make the forecast

See {doc}`trained_models` for details.
"""

inner_steps = 24  # save model outputs once every 24 hours
outer_steps = 10 * 24 // inner_steps  # total of 10
timedelta = np.timedelta64(1, 'h') * inner_steps
times = (np.arange(outer_steps) * inner_steps)  # time axis in hours

# initialize model state
inputs = model.inputs_from_xarray(eval_era5.isel(time=0))
input_forcings = model.forcings_from_xarray(eval_era5.isel(time=0))
rng_key = jax.random.key(42)  # optional for deterministic models
initial_state = model.encode(inputs, input_forcings, rng_key)

# use persistence for forcing variables (SST and sea ice cover)
all_forcings = model.forcings_from_xarray(eval_era5.head(time=1))

# make forecast
final_state, predictions = model.unroll(
    initial_state,
    all_forcings,
    steps=outer_steps,
    timedelta=timedelta,
    start_with_input=True,
)
predictions_ds = model.data_to_xarray(predictions, times=times)

#geopotential_500mb = predictions_ds.sel(level=500)
#temp = predictions_ds.sel(level=860)
geopotential_500mb = predictions_ds.sel(level=500)

output_directory = '/home/ennisk'
# os.makedirs(output_directory, exist_ok=True)
# output_path_nc = os.path.join(output_directory, 'NGCM_may2002_500mb.nc')


# predictions_ds_500mb = xarray.Dataset({
#     'geopotential': geopotential_500mb.geopotential
# })

# Save to NetCDF
#predictions_ds_500mb.to_netcdf(output_path_nc)

# predictions_ds_temp = xarray.Dataset({
#     'temperature': temp.temperature
# })

# # Save to NetCDF
# output_path_nc = os.path.join(output_directory, 'NGCM_may2002_temp.nc')
# predictions_ds_temp.to_netcdf(output_path_nc)


"""## Compare forecast to ERA5

See [WeatherBench2](https://sites.research.google/weatherbench/) for more comprehensive evaluations and archived NeuralGCM forecasts.
"""

target_trajectory = model.inputs_from_xarray(
    eval_era5
    .thin(time=(inner_steps // data_inner_steps))
    .isel(time=slice(outer_steps))
)
target_data_ds = model.data_to_xarray(target_trajectory, times=times)

era5_geopotential_500mb = target_data_ds.sel(level=500)['geopotential']
ngcm_geopotential_500mb = predictions_ds.sel(level=500)['geopotential']

# Combine both datasets into a single dataset for comparison
combined_ds_500mb = xr.concat(
    [era5_geopotential_500mb, ngcm_geopotential_500mb], 
    dim='model'
)
combined_ds_500mb.coords['model'] = ['ERA5', 'NeuralGCM']

# Specify the output file path
output_path_nc = '/home/ennisk/NGCM_ERA5_500mb_geopotential_comparison.nc'

# Save the combined dataset to a NetCDF file
combined_ds_500mb.to_netcdf(output_path_nc)

# combined_ds = xarray.concat([target_data_ds, predictions_ds], 'model')
# combined_ds.coords['model'] = ['ERA5', 'NeuralGCM']
# output_file_path = '/home/ennisk/combined_trajectories_geo.nc'
# combined_ds.to_netcdf(output_file_path)
# # Visualize ERA5 vs NeuralGCM trajectories
# combined_ds.temperature.sel(level=500).plot(
#     x='longitude', y='latitude', row='time', col='model', robust=True, aspect=2, size=2
# )

# plot_path = os.path.join(
#     output_directory, 'ERA5_vs_NeuralGCM_temp_comparison.png')
# plt.savefig(plot_path, dpi=400, bbox_inches='tight')
# plt.close()


